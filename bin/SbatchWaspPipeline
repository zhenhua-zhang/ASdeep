#!/bin/bash
# ASE analysis pipeline by fastp, STAR, WASP, and SAMtools
set -Ee -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

# Setup working directories for current project.
cat >/dev/null << EOF
How the working tree looks like
WORKDIR/
├── [genomeDir/]
├── [snpH5db/]
├── [fastaH5db/]
├── optDir/
│   └── FASTQID/
│       ├── fastpOptDir/
│       ├── starOptDir/
│       └── waspOptDir/
└── tmpDir
    └── FASTQID
        ├── fastpTmpDir/
        ├── starTmpDir/
        └── waspTmpDir/
            ├── perChrom/
            └── starMapping/
EOF

cat >/dev/null <<EOF
WASP (v0.3.4) dependencies:
Python 3.6.3
numexpr 2.7.1
numpy 1.19.4
pysam 0.16.0.1
scipy 1.5.4
tables 3.6.1
EOF

# ENVs {
export ASEPL_VERSION
ASEPL_VERSION="0.1.0"
ASEPL_FILENAME=$(basename "$0")
# } // ENVs


ERRO() {
    echo -e "[E]: $1" >&2 && exit -1
}

WARN() {
    echo -e "[W]: $1" >&2
}

INFO() {
    echo -e "[I]: $1"
}

echo_version() {
    cat << EOF

$ASEPL_FILENAME, Version ${ASEPL_VERSION:=UNKNOWN}

EOF
}

echo_help() {
    cat <<EOF

$ASEPL_FILENAME, Version ${ASEPL_VERSION:=UNKNOWN}

It is recommended to use the a configuration file instead of commandline
arguments and flags. Please check the \`./config\` file for more information.

Help:
  -c|--config    Optional.
      The confituration file to supply values for the variables
  -w|--workDir    Required.
      The working directory.
  -i|--fastqId    Required.
      The FASTQ files id.
  -p|--fastqDir    Required.
      The directory to the FASTQ files.
  -g|--genomeDir    Required.
      The path to the genome index.
  --genomeFastaFile    Required.
      The path to the FASTA file of genome file.
  --genomeAnnotationFile    Required.
      The path to the gene feature file.
  --snpH5dbPath    Required.
      The path to the HDF5 database for variants
  --snp2h5Exe    Optional.
      The path to the executable snp2h5 by WASP pipeline.
  --vcfFileDir    Optional
      The path to the variant call format (VCF) file holding variants information.
  --chromInfoFile    Required.
      The file holding chromosome information.
  --fastaH5dbPath    Optional
      The path to the HDF5 database for geome sequence
  --fasta2h5Exe   Optional
      The path to the executable fasta2h5 by WASP pipeline.
  --waspDir  Required.
      The path to the WASP tool.
  --pyEnv  Required.
      The path to the python virtual enviroment.
  --sampleIdFile
      The path to file holding sample ID.
  -h|--help    Optional. Action: print_info
    Print this help context and exit.
  -V|--version    Optional. Action: store_true
    Print version of current script and exit.

More information please contact Zhenhua Zhang <zhenhua.zhang217@gmail.com>

EOF
}

lopt="config:,workDir:,fastqId:,fastqDir:,fastqPrefix:,fastqSuffix:,fastpExe:,"
lopt=$lopt"genomeDir:,genomeFastaFile:,genomeAnnotationFile:,snpH5dbPath:,"
lopt=$lopt"snp2h5Exe:,vcfFileDir:,vcfFilePrefix:,vcfFileSuffix:,chromInfoFile:,"
lopt=$lopt"fastaH5dbPath:,fasta2h5Exe:,waspDir:,pyEnv:,sampleIdFile:,help,version"
opt=$(getopt -l $lopt -- "c:w:i:p:g:hv" "$@")
eval set -- $opt
while true; do
    case $1 in
        -c|--config) shift && config=$1 && break ;;
        -w|--workDir) shift && workDir=$1 ;;

        -i|--fastqId) shift && fastqId=$1 ;;
        -p|--fastqDir) shift && fastqDir=$1 ;;
        --fastqPrefix) shift && fastqPrefix=$1 ;;
        --fastqSuffix) shift && fastqSuffix=$1 ;;

        --fastpExe) shift && fastpExe=$1 ;;

        -g|--genomeDir) shift && genomeDir=$1 ;;
        --chromInfoFile) shift && chromInfoFile=$1 ;;
        --genomeFastaFile) shift && genomeFastaFile=$1;;
        --genomeAnnotationFile) shift && genomeAnnotationFile=$1 ;;

        --snpH5dbPath) shift && snpH5dbPath=$1 ;;
        --snp2h5Exe) shift && snp2h5Exe=$1 ;;

        --vcfFileDir) shift && vcfFileDir=$1 ;;
        --vcfFilePrefix) shift && vcfFilePrefix=$1 ;;
        --vcfFileSuffix) shift && vcfFileSuffix=$1 ;;

        --fastaH5dbPath) shift && fastaH5dbPath=$1 ;;
        --fasta2h5Exe) shift && fasta2h5Exe=$1 ;;

        --waspDir) shift && waspDir=$1 ;;
        --pyEnv) shift && pyEnv=$1 ;;

        --sampleIdFile) shift && sampleIdFile=$1 ;;

        -h|--help) echo_help && exit 0 ;;
        -v|--version) echo_version && exit 0 ;;
        --) shift && break ;;
    esac
    shift
done

# Check config file, otherwise use CLI options instead. {
if [ "xxx"$config == "xxx" ]; then
    workDir=${workDir:?-w/--workDir is required}
    fastqId=${fastqId:?-i/--fastqId is required}
    fastqDir=${fastqDir:?-p/--fastqDir is required}

    if [ $genomeDir"xxx" == "xxx" ]; then
        if [ $genomeFastaFile"xxx" == "xxx" ]; then
            ERRO "Either -g/--genomeDir or -f/--genomeFastaFile should be given!"
        fi

        # Setup the path of STAR genome index
        genomeDir=${genomeDir:=$workDir/genomeDir}
    else
        if [ $genomeFastaFile"xxx" != "xxx" ]; then
            ERRO "Either -g/--genomeDir or -f/--genomeFastaFile should be given, but not both!"
        fi
    fi
    fastpExe=${fastpExe:=~/tools/bin/fastp}
    fastqPrefix=${fastqPrefix:="/"}
    fastqSuffix=${fastqSuffix:=.fq.gz}

    snp2h5Exe=${snp2h5Exe:=snp2h5}
    fasta2h5Exe=${fasta2h5Exe:=fasta2h5}

    vcfFilePrefix=${vcfFilePrefix:=gonl.chr}
    vcfFileSuffix=${vcfFileSuffix:=.snps_indels.r5.3.vcf.gz}
else
    if [ -f $config ]; then
        source $config
    else
        ERRO "Not found $config to read"
    fi
fi
# } // Check config file, otherwise use CLI options instead.

mkdir -p $workDir/logdir \
    $workDir/tmpDir/$fastqId/{fastp,star,wasp}TmpDir \
    $workDir/optDir/$fastqId/{fastp,star,wasp}OptDir \

afterok="--dependency=afterok"  # NOTE: the colon after the afterok is maully added

#
## FASTP: Preprocessing fastq files. {
#
stepName=FastpPreproc
mem=5G
cpus=5  # Current only for paired-end FASTQs. It can only use up to 16 CPUs.
time=0:29:00

fastqFileR1=$fastqDir/$fastqPrefix$fastqId"_R1"$fastqSuffix
fastqFileR2=$fastqDir/$fastqPrefix$fastqId"_R2"$fastqSuffix
fastpTmpDir=$workDir/tmpDir/$fastqId/fastpTmpDir

fastpPreprocJobId=$(sbatch --time=$time --cpus=$cpus --mem=$mem \
    --output=$workDir/logdir/%j-$fastqId-$stepName.log \
    --job-name=$fastqId-$stepName \
    <<EOF | cut -d' ' -f4
#!/bin/bash
set -Eex -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

$fastpExe \
    --in1 $fastqFileR1 \
    --in2 $fastqFileR2 \
    --out1 $fastpTmpDir/${fastqId}_R1_paired.fq.gz \
    --out2 $fastpTmpDir/${fastqId}_R2_paired.fq.gz \
    --unpaired1 $fastpTmpDir/${fastqId}_R1_unpaired.fq.gz \
    --unpaired2 $fastpTmpDir/${fastqId}_R2_unpaired.fq.gz  \
    --failed_out $fastpTmpDir/${fastqId}_failed.fq.gz \
    --html $fastpTmpDir/${fastqId}_report.html \
    --json $fastpTmpDir/${fastqId}_report.json \
    --thread $cpus \
    --overrepresentation_sampling 100 \
    --detect_adapter_for_pe \
    --cut_front \
    --cut_tail \
    --correction \
    --trim_poly_g \
    --trim_poly_x \
    --dont_overwrite
EOF
)
echo $stepName was submitted: $fastpPreprocJobId ...
# } // FASTP: Preprocessing fastq files.

#
## STAR: Generate STAR genome index {
#
# TODO: Conflicts between CLI options. If genomeDir is given, genomeFastaFile is not mandatory
# Create STAR genome index. It requires at least 120G memory and 1.5 hours when using 15 cores.
# The index was made on human genome build 37, using transcript annotations (V75) downloaded from
# Ensembl. The genome index should be constructed with annotations.
if [ -d $genomeDir ]; then
    INFO "Found $genomeDir, supposing it as a legal STAR genome index, skip STARGenomeIndex"
    dependency=$afterok:$fastpPreprocJobId
else
    [[ $genomeFastaFile"xxx" == "xxx" ]] \
        && ERRO "No genome index found, please specify genome fasta file to create the genome index"

    [[ $genomeAnnotationFile"xxx" == "xxx" ]] \
        && ERRO "No genome index found, please specify genome annotation file to create the genome index"

    mkdir -p $workDir/genomeDir

    stepName=STARBuildGenomeIndex
    mem=150G
    cpus=15
    time=0:59:00

    genomeIndexPrefix=${genomeIndexPrefix:=STARGenomeIndex}

    STARGenomeIndexJobId=$(sbatch --time=$time --cpus=$cpus --mem=$mem \
        --output=$workDir/logdir/%j-$stepName.log \
        --job-name=$stepName \
        <<EOF | cut -d' ' -f4
#!/bin/bash
set -Eex --o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

module purge && module load STAR/2.5.1b-foss-2015b && module list

STAR --runMode genomeGenerate \
  --genomeDir $genomeDir \
  --genomeFastaFiles $genomeFastaFile \
  --sjdbGTFfile $genomeAnnotationFile \
  --runThreadN $cpus \
  --outFileNamePrefix $genomeIndexPrefix
EOF
)
    echo "$stepName was submitted: $STARGenomeIndexJobId ..."
    dependency=$afterok:$fastpPreprocJobId:$STARGenomeIndexJobId
fi
# } // STAR: Generate STAR genome index

#
## STAR: Mapping reads to genome {
#
stepName=STARMapping
mem=50G  # For human genome, it requires at least 40G memory.
cpus=15
time=0:59:00

readFilesInR1=$fastpTmpDir/${fastqId}_R1_paired.fq.gz
readFilesInR2=$fastpTmpDir/${fastqId}_R2_paired.fq.gz
outSAMattrRGline="ID:$fastqId SM:$fastqId PL:ILLUMINA"

STARMappingJobId=$(sbatch $dependency --time=$time --cpus=$cpus --mem=$mem \
    --output=$workDir/logdir/%j-$fastqId-$stepName.log \
    --job-name=$fastqId-$stepName \
    <<EOF | cut -d' ' -f4
#!/bin/bash
set -Eex -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

mappingOutPrefix=$workDir/tmpDir/$fastqId/starTmpDir/$fastqId
module purge && module load STAR/2.5.1b-foss-2015b && module list
STAR --runMode alignReads \
    --genomeDir $genomeDir \
    --runThreadN $cpus \
    --readFilesIn $readFilesInR1 $readFilesInR2 \
    --readFilesCommand zcat \
    --outSAMtype BAM SortedByCoordinate \
    --outSAMattrRGline $outSAMattrRGline \
    --twopassMode "Basic" \
    --outFileNamePrefix \$mappingOutPrefix

module purge && module load SAMtools && module list
samtools index -@ $cpus \$mappingOutPrefix*.bam
EOF
)
echo "$stepName was submitted: $STARMappingJobId ..."
# } // Mapping reads to genome 

#
## WASP: Generate SNP HDF5 database for WASP {
#
stepName=WaspCreateSnpHdf5Database
if [ -d $snpH5dbPath ]; then
    INFO "Found $snpH5dbPath, supposing it as a legal SNP HDF5 database, skip $stepName"
    dependency=$afterok:$STARMappingJobId
else
    mem=5G
    cpus=1
    time=0:59:00

    snpH5dbPath=$workDir/snpH5db
    WaspCreateSnpHdf5DatabaseJobId=$(sbatch --time=$time --cpus=$cpus --mem=$mem \
        --array=1-22 \
        --output=$workDir/logdir/%A_%a-$stepName.log \
        --job-name=$stepName \
        <<EOF | cut -f4 -d ' '
#!/bin/bash
set -Eex -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

module purge && module load HDF5/1.8.14-foss-2015b && module list

chromId=\${SLURM_ARRAY_TASK_ID:=22}
vcfFile=$vcfFileDir/$vcfFilePrefix\$chromId$vcfFileSuffix

mkdir -p $snpH5dbPath/\$chromId
$snp2h5Exe \
	--chrom $chromInfoFile \
	--format vcf \
	--snp_tab $snpH5dbPath/\$chromId/snps_tab.h5 \
	--snp_index $snpH5dbPath/\$chromId/snps_index.h5 \
	--haplotype $snpH5dbPath/\$chromId/haplotype.h5 \
	\$vcfFile
EOF
)
    echo "$stepName was submitted: $WaspCreateSnpHdf5DatabaseJobId ..."
    dependency=$afterok:$STARMappingJobId:$WaspCreateSnpHdf5DatabaseJobId
fi
# } // Generate SNP HDF5 database for WASP

#
## WASP: Generage FASTA HDF5 database for WASP {
#
stepName=WaspCreateFastaHdf5Database
if [ -d $fastaH5dbPath ]; then
    INFO "Found $fastaH5dbPath, supposing it as a legal FASTA HDF5 database, skip $stepName"
else
    mem=5G
    cpus=1
    time=0:59:00
    fastaH5dbPath=$workDir/fastaH5db

    WaspCreateFastaHdf5DatabaseJobId=$(sbatch --time=$time --cpus=$cpus --mem=$mem \
        --output=$workDir/logdir/%j-$stepName.log \
        --job-name=$stepName \
        <<EOF | cut -f4 -d' '
#!/bin/bash
set -Eex -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

module purge && module load HDF5/1.8.14-foss-2015b && module list

mkdir -p $fastaH5dbPath \
    && csplit -s -f $fastaH5dbPath/chr -b '%d' ${genomeFastaFile} '/>/' {22} \
    && rm -f chr{0,23}

for chr_file in $fastaH5dbPath/chr*; do
    $fasta2h5Exe \
        --chrom $chromInfoFile \
        --seq \${chr_file}.h5 \
        \${chr_file} \
        && rm -f \${chr_file}
done
EOF
)
    echo "$stepName was submitted: $WaspCreateFastaHdf5DatabaseJobId ..."
fi
# } // Generage FASTA HDF5 database for WASP


#
## WASP: Find intersected SNPs {
#
stepName=WaspRMBFindIntersectedSnps
mem=8G
cpus=1
time=0:29:00

WaspRMBFindIntersectedSnpsJobId=$(sbatch $dependency \
    --time=$time --mem=$mem --cpus=$cpus \
    --ntasks=1 --array=1-22 \
    --output=$workDir/logdir/%A_%a-$fastqId-$stepName.log \
    --job-name=$fastqId-$stepName \
    <<EOF | cut -f4 -d' '
#!/bin/bash
set -Eex -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

chromId=\${SLURM_ARRAY_TASK_ID:=22}

# Split a huge BAM file by chromosome.
module purge && module load SAMtools && module list

perChromDir=$workDir/tmpDir/$fastqId/waspTmpDir/perChrom
mkdir -p \$perChromDir/\$chromId

samtools view -hb \
    -o \$perChromDir/\$chromId/${fastqId}_\$chromId.bam \
    $workDir/tmpDir/$fastqId/starTmpDir/*.bam \
    \$chromId
samtools index \$perChromDir/\$chromId/${fastqId}_\$chromId.bam

# Find intersecting SNPs
module purge && module load HDF5/1.8.14-foss-2015b Python/3.6.3-foss-2015b && module list
if [ $pyEnv"xxx" != "xxx" ]; then source $pyEnv/bin/activate; fi

# find_intersecting_snps.py
python $waspDir/mapping/find_intersecting_snps.py \
    --is_paired_end \
    --is_sorted \
    --output_dir \$perChromDir/\$chromId \
    --snp_tab $snpH5dbPath/\$chromId/snps_tab.h5 \
    --snp_index $snpH5dbPath/\$chromId/snps_index.h5 \
    --haplotype $snpH5dbPath/\$chromId/haplotype.h5 \
    --samples $(grep -w $fastqId $sampleIdFile | cut -f2) \
    \$perChromDir/\$chromId/${fastqId}_\$chromId.bam
EOF
)
echo "$stepName was submitted: $WaspRMBFindIntersectedSnpsJobId ..."
# } // Find intersected SNPs


#
## STAR: Remapping by STAR for WASP {
#
dependency=$afterok:$WaspRMBFindIntersectedSnpsJobId
stepName=WaspRMBRemapping
mem=60G
cpus=15
time=0:59:00

WaspRMBRemappingJobId=$(sbatch $dependency \
    --time=$time --mem=$mem --cpus=$cpus \
    --output=$workDir/logdir/%j-$fastqId-$stepName.log \
    --job-name=$fastqId-$stepName \
    <<EOF | cut -f4 -d' '
#!/bin/bash
set -Eex -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

mkdir -p $workDir/tmpDir/$fastqId/waspTmpDir/starMapping

waspTmpDir=$workDir/tmpDir/$fastqId/waspTmpDir/perChrom
readFilesIn_1=\$(ls -m \$waspTmpDir/**/*remap.fq1.gz | tr -d "\\n ")
readFilesIn_2=\$(ls -m \$waspTmpDir/**/*remap.fq2.gz | tr -d "\\n ")

outSAMattrRGline="ID:$fastqId SM:$fastqId PL:ILLUMINA"
mappingOutPrefix=$workDir/tmpDir/$fastqId/waspTmpDir/starMapping/waspStarRemap

module purge && module load STAR/2.5.1b-foss-2015b && module list
STAR --runMode alignReads \
    --genomeDir $genomeDir \
    --runThreadN $cpus \
    --readFilesIn \$readFilesIn_1 \$readFilesIn_2 \
    --readFilesCommand zcat \
    --outSAMtype BAM SortedByCoordinate \
    --outSAMattrRGline \$outSAMattrRGline \
    --twopassMode "Basic" \
    --outFileNamePrefix \$mappingOutPrefix

# Create index files for BAMs
module purge && module load SAMtools && module list
samtools index -@ $cpus \$mappingOutPrefix*.bam
EOF
)
echo "$stepName was submitted: $WaspRMBRemappingJobId ..."
# } // STAR: Remapping by STAR for WASP

#
## WASP: RMB filtering and removing duplication {
#
dependency=$afterok:$WaspRMBRemappingJobId
stepName=WaspRMBFilterAndRmDup
mem=10G
cpus=1
time=0:19:00

waspDir=${waspDir:=~/tools/WASP}
WaspRMBFilterAndRmDupJobId=$(sbatch $dependency \
    --time=$time --mem=$mem --cpus=$cpus --ntasks=1 --array=1-22 \
    --output=$workDir/logdir/%A_%a-$fastqId-$stepName.log \
    --job-name=$fastqId-$stepName \
    <<EOF | cut -f4 -d' '
#!/bin/bash
set -Eex -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

chromId=\${SLURM_ARRAY_TASK_ID:=22}
perChromDir=$workDir/tmpDir/$fastqId/waspTmpDir/perChrom

# Split a huge BAM file by chromosome.
module purge && module load SAMtools && module list
samtools view -hb \
    -o \$perChromDir/\$chromId/${fastqId}_\${chromId}.remap.bam \
    $workDir/tmpDir/$fastqId/waspTmpDir/starMapping/*.bam \
    \$chromId

# Find intersecting SNPs
module purge && module load HDF5/1.8.14-foss-2015b Python/3.6.3-foss-2015b && module list
if [ $pyEnv"xxx" != "xxx" ]; then source $pyEnv/bin/activate; fi

## Conquer
toRemapBAM=\$perChromDir/\$chromId/${fastqId}_\${chromId}.to.remap.bam
remapBAM=\$perChromDir/\$chromId/${fastqId}_\${chromId}.remap.bam
filterRemappedReadsPy=$waspDir/mapping/filter_remapped_reads.py
remapKeptBam=\$perChromDir/\$chromId/${fastqId}_\${chromId}.remap.keep.bam
python \$filterRemappedReadsPy \$toRemapBAM \$remapBAM \$remapKeptBam

## Merge original and remapped BAM
module purge && module load SAMtools && module list
keptBAM=\$perChromDir/\$chromId/${fastqId}_\$chromId.keep.bam
keptMergedBAM=\$perChromDir/\$chromId/${fastqId}_\$chromId.keep.merged.bam
keptMergedSortedBAM=\${keptMergedBAM/.bam/.sort.bam}

samtools merge -f \$keptMergedBAM \$remapKeptBam \$keptBAM
samtools sort -@ $cpus -o \$keptMergedSortedBAM \$keptMergedBAM
samtools index -@ $cpus \$keptMergedSortedBAM

# Remove duplicates
rmdupPePy=$waspDir/mapping/rmdup_pe.py
keptMergedSortedRmdupBam=\${keptMergedSortedBAM/.bam/.rmdup.bam}

module purge && module load HDF5/1.8.14-foss-2015b Python/3.6.3-foss-2015b && module list
if [ $pyEnv"xxx" != "xxx" ]; then source $pyEnv/bin/activate; fi

python \$rmdupPePy \$keptMergedSortedBAM \$keptMergedSortedRmdupBam

# Sort and index BAM
module purge && module load SAMtools && module list

keptMergedSortedRmdupSortBam=\${keptMergedSortedRmdupBam/.bam/.sort.bam}
samtools sort -@ $cpus -o \$keptMergedSortedRmdupSortBam \$keptMergedSortedRmdupBam
samtools index -@ $cpus \$keptMergedSortedRmdupSortBam

# Get Allele-specific read counts
module purge && module load HDF5/1.8.14-foss-2015b Python/3.6.3-foss-2015b && module list
if [ $pyEnv"xxx" != "xxx" ]; then source $pyEnv/bin/activate; fi

individual=$(grep -w $fastqId $sampleIdFile | cut -f2)
refAlleleCountsFile=\$perChromDir/\$chromId/${fastqId}_\$chromId.refAlleleCounts.h5
altAlleleCountsFile=\$perChromDir/\$chromId/${fastqId}_\$chromId.altAlleleCounts.h5
otherAlleleCountsFile=\$perChromDir/\$chromId/${fastqId}_\$chromId.otherAlleleCounts.h5
readsCounts=\$perChromDir/\$chromId/${fastqId}_\$chromId.allCounts.h5
# readsCountsInText=\$perChromDir/\$chromId/${fastqId}_\$chromId.readCountsInText.txt

python $waspDir/CHT/bam2h5.py \
    --chrom $chromInfoFile \
    --test_chrom \$chromId \
    --snp_index $snpH5dbPath/\$chromId/snps_index.h5 \
    --snp_tab $snpH5dbPath/\$chromId/snps_tab.h5 \
    --haplotype $snpH5dbPath/\$chromId/haplotype.h5 \
    --individual \$individual \
    --ref_as_counts \$refAlleleCountsFile \
    --alt_as_counts \$altAlleleCountsFile \
    --other_as_counts \$otherAlleleCountsFile \
    --read_counts \$readsCounts \
    \$keptMergedSortedRmdupSortBam
    # --txt_counts \$readsCountsInText
EOF
)

echo "$stepName was submitted: $WaspRMBFilterAndRmDupJobId ..."
# } // WASP: RMB filtering and removing duplication

#
## Collect output and clean up {
#
dependency=$afterok:$WaspRMBFilterAndRmDupJobId
stepName=CollectOutputAndCleanup
mem=20G
cpus=5
time=0:19:00

CollectOutputAndCleanupJobId=$(sbatch $dependency \
    --time=$time --mem=$mem --cpus=$cpus --ntasks=1 \
    --output=$workDir/logdir/%j-$fastqId-$stepName.log \
    --job-name=$fastqId-$stepName \
    <<EOF | cut -d' ' -f4
#!/bin/bash
set -Eex -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

cp -fr $workDir/tmpDir/$fastqId/fastpTmpDir/*.{html,json} $workDir/optDir/$fastqId/fastpOptDir
# cp -fr $workDir/tmpDir/$fastqId/starTmpDir/* $workDir/optDir/$fastqId/starOptDir

for chr in {1..22}; do
    if [[ -d $workDir/tmpDir/$fastqId/waspTmpDir/perChrom/\$chr ]]; then
        mkdir -p $workDir/optDir/$fastqId/waspOptDir/perChrom/\$chr
        cp -fr $workDir/tmpDir/$fastqId/waspTmpDir/perChrom/\$chr/*.h5 \
            $workDir/optDir/$fastqId/waspOptDir/perChrom/\$chr
    fi
done

# cat $workDir/tmpDir/$fastqId/waspTmpDir/perChrom/*/*.readCountsInText.txt \
#     > $workDir/optDir/$fastqId/waspOptDir/$fastqId.readCountsInText.txt

module purge && module load SAMtools && module list
samtools merge -fcp -@ $cpus \
    $workDir/optDir/$fastqId/waspOptDir/$fastqId.keep.merge.rmdup.bam \
    $workDir/tmpDir/$fastqId/waspTmpDir/perChrom/*/*.keep.merged.sort.rmdup.sort.bam

samtools sort -@ $cpus \
    -o $workDir/optDir/$fastqId/waspOptDir/$fastqId.keep.merge.rmdup.sort.bam \
    $workDir/optDir/$fastqId/waspOptDir/$fastqId.keep.merge.rmdup.bam

samtools index -@ $cpus \
    $workDir/optDir/$fastqId/waspOptDir/$fastqId.keep.merge.rmdup.sort.bam

rm -fr $workDir/optDir/$fastqId/waspOptDir/$fastqId.keep.merge.rmdup.bam
rm -fr $workDir/tmpDir/$fastqId
EOF
)

echo "$stepName was submitted. Job id: $CollectOutputAndCleanupJobId ..."
# } // Collect output and clean up
