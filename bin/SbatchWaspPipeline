#!/bin/bash
# ASE analysis pipeline by fastp, STAR, WASP, and SAMtools

[[ -f ./WaspPipelineUtils.sh ]] && source ./WaspPipelineUtils.sh || exit -1
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

set -E -o pipefail

#
## NOTE
#
# 1. For one sample with paired-end results about 2G in total, the intermediate
# files could go up to 30G. Please make sure you have enough space on the devices.

#
## Working directory tree
#
# WORKDIR/
# ├── [genomeDir/]
# ├── [snpH5db/]
# ├── optDir/
# │   └── FASTQID/
# │       ├── fastpOptDir/
# │       ├── starOptDir/
# │       ├── waspOptDir/
# │       ├── gatkOptDir/
# │       └── rasqualOptDir/
# └── tmpDir
#     └── FASTQID/
#         ├── fastpTmpDir/
#         ├── starTmpDir/
#         ├── waspTmpDir/
#         │   └── starMapping/
#         ├── gatkTmpDir/
#         └── rasqualTmpDir/

#
## WASP (v0.3.4) dependencies:
#
# Python 3.6.3
# Python packages:
#     numexpr 2.7.1
#     numpy 1.19.4
#     pysam 0.16.0.1
#     scipy 1.5.4
#     tables 3.6.1

opt=$(getopt -o "c:hv" -l "conf:,help,version" -- "$@")
eval set -- $opt
while true; do
    case $1 in
        -c|--conf) shift && config=$1 && break ;;
        -h|--help) echoHelp && exit 0 ;;
        -v|--version) echoVersion && exit 0 ;;
        --) shift && break ;;
    esac
    shift
done

[[ -f ${config:?-c/--conf is required} ]] \
    && source $config || echoErro "Not found $config to read"

projDir=/groups/umcg-bios/tmp01/users/umcg-zzhang/projects/wp_ase_dlp

workDir=$projDir/outputs/aseQuan
cohortId=CODAM

logDir=$workDir/logDir 

tmpDir=$workDir/tmpDir
fastpTmpDir=$tmpDir/$fastqId/fastpTmpDir
starTmpDir=$tmpDir/$fastqId/starTmpDir
waspTmpDir=$tmpDir/$fastqId/waspTmpDir
gatkTmpDir=$tmpDir/$fastqId/gatkTmpDir
rasqualTmpDir=$tmpDir/$fastqId/rasqualTmpDir

optDir=$workDir/$cohortId/optDir
fastpOptDir=$OptDir/$fastqId/fastpOptDir
starOptDir=$OptDir/$fastqId/starOptDir
waspOptDir=$OptDir/$fastqId/waspOptDir
gatkOptDir=$OptDir/$fastqId/gatkOptDir
rasqualOptDir=$OptDir/$fastqId/rasqualOptDir

genomeDir=$workDir/genomeDir
genomeFastaFile=
genomeAnnotationFile=

vcfFile=$projDir/outputs/phasing/all-CODAM-singleAlt.vcf.gz
chromInfoFile=$projDir/inputs/Ensembl_references/human_g1k_v37_chrom_info.txt

fastqId=AD10W1ACXX-1-11
fastqDir=$workDir/tmpDir
fastqPrefix=
fastqSuffix=.fq.gz

sampleIdFile=$projDir/inputs/idmapping/GTE_BIOS_empirical_match_30-03-2016_usable_GTE_with_NTR.txt
sampleId=$(grep -w $fastqId $sampleIdFile | cut -f2)

afterok="--dependency=afterok"  # NOTE: the colon after the afterok is maully added

mkdir -p $logDir \
    $tmpDir/$fastqId/{fastp,star,wasp,gatk,rasqual}TmpDir \
    $optDir/$fastqId/{fastp,star,wasp,gatk,rasqual}OptDir \

#
## STAR: Generate STAR genome index {
#
stepName=STARBuildGenomeIndex
if [ -d $genomeDir ]; then
    echoWarn "Found $genomeDir, skip $stepName"
else
    [[ $genomeFastaFile"xxx" == "xxx" ]] \
        && echoErro "No genome index found, please give genome fasta file"

    [[ $genomeAnnotationFile"xxx" == "xxx" ]] \
        && echoErro "No genome index found, please give genome annotation file"

    mkdir -p $workDir/genomeDir

    mem=150G
    cpus=15
    time=0:59:00
    STARGenomeIndexJobId=$(sbatch \
        --mem=$mem \
        --time=$time \
        --cpus-per-task=$cpus \
        --job-name=$stepName \
        --output=$workDir/logDir/%j-$stepName.log \
        <<EOF | cut -d' ' -f4
#!/bin/bash
set -Ee -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

module load STAR/2.6.1c-foss-2018b
module list

STAR \
    --runMode genomeGenerate \
    --genomeDir $genomeDir \
    --genomeFastaFiles $genomeFastaFile \
    --sjdbGTFfile $genomeAnnotationFile \
    --runThreadN $cpus \
    --outFileNamePrefix $genomeDir/starGenomeIndex
EOF
)
    echoInfo "$stepName was submitted: $STARGenomeIndexJobId ..."
fi
# } // STAR: Generate STAR genome index


#
## WASP: Generate SNP HDF5 database for WASP {
#
stepName=WaspCreateSnpHdf5Database
if [ -d $snpH5dbPath ]; then
    echoWarn "Found $snpH5dbPath, skip $stepName"
else
    mem=5G
    cpus=1
    time=0:19:00

    # snpH5dbPath=$workDir/snpH5db
    WaspCreateSnpHdf5DatabaseJobId=$(sbatch \
        --mem=$mem \
        --time=$time \
        --cpus-per-task=$cpus \
        --job-name=$stepName \
        --output=$logDir/%j-%u-$stepName.log \
        <<EOF | cut -f4 -d ' '
#!/bin/bash
set -Ee -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

mkdir -p $snpH5dbPath
mkdir -p $tmpDir/snpH5dbTmpDir

# Split the VCF by chromosome
module load BCFtools
module list
for chr in {1..22}; do
    bcftools view \
        -O z
        -o $tmpDir/snpH5dbTmpDir/${vcfFile/.vcf.gz/-chr${chr}.vcf.gz} \
        $vcfFile ${chr}
done

# Generate SNP HDF5 database
module load HDF5/1.8.14-foss-2018b
module list

~/tools/bin/snp2h5 \
	--chrom $chromInfoFile \
	--format vcf \
	--snp_tab $snpH5dbPath/snps_tab.h5 \
	--snp_index $snpH5dbPath/snps_index.h5 \
	--haplotype $snpH5dbPath/haplotype.h5 \
    $tmpDir/snpH5dbTmpDir/${vcfFile/.vcf.gz/}-chr*.vcf.gz

# rm -fr $tmpDir/snpH5dbTmpDir
EOF
)
    echoInfo "$stepName was submitted: $WaspCreateSnpHdf5DatabaseJobId ..."
fi
# } // Generate SNP HDF5 database for WASP


#
## FASTP: Preprocessing fastq files. {
#
dependency=$afterok:$STARMappingJobId:$WaspCreateSnpHdf5DatabaseJobId
if [[ $dependency == "--afterok::" ]]; then dependency=""; fi

stepName=FastpPreproc
mem=5G
cpus=5
time=0:19:00

fastpPreprocJobId=$(sbatch $dependency \
    --mem=$mem \
    --time=$time \
    --cpus-per-task=$cpus \
    --job-name=$fastqId-$stepName \
    --output=$logDir/%j-$fastqId-$stepName.log \
    <<EOF | cut -d' ' -f4
#!/bin/bash
set -Ee -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

module load GCC/7.3.0-2.30 # fastp was compiled using GCC v7.3.0
module list

# add a CLI option to fastq files
~/tools/bin/fastp \
    --in1 $fastqDir/$fastqPrefix$fastqId"_R1"$fastqSuffix \
    --in2 $fastqDir/$fastqPrefix$fastqId"_R2"$fastqSuffix \
    --out1 $fastpTmpDir/${fastqId}_paired_R1.fq.gz \
    --out2 $fastpTmpDir/${fastqId}_paired_R2.fq.gz \
    --unpaired1 $fastpTmpDir/${fastqId}_unpaired_R1.fq.gz \
    --unpaired2 $fastpTmpDir/${fastqId}_unpaired_R2.fq.gz  \
    --failed_out $fastpTmpDir/${fastqId}_failed.fq.gz \
    --html $fastpTmpDir/${fastqId}_report.html \
    --json $fastpTmpDir/${fastqId}_report.json \
    --thread $cpus \
    --overrepresentation_sampling 100 \
    --detect_adapter_for_pe \
    --cut_front \
    --cut_tail \
    --correction \
    --trim_poly_g \
    --trim_poly_x
EOF
)
echoInfo $stepName was submitted: $fastpPreprocJobId ...
# } // FASTP: Preprocessing fastq files.


#
## STAR: Mapping reads to genome {
#
dependency=$afterok:$fastpPreprocJobId
stepName=STARMapping
mem=50G  # For human genome, it requires at least 40G memory.
cpus=5
time=0:45:00

STARMappingJobId=$(sbatch $dependency \
    --mem=$mem \
    --time=$time \
    --cpus-per-task=$cpus \
    --job-name=$fastqId-$stepName \
    --output=$workDir/logDir/%j-$fastqId-$stepName.log \
    <<EOF | cut -d' ' -f4
#!/bin/bash
set -Ee -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

# Mapping
module load STAR/2.6.1c-foss-2018b
module list

STAR --runMode alignReads \
    --genomeDir $genomeDir \
    --runThreadN $cpus \
    --readFilesIn $fastpTmpDir/${fastqId}_R{1,2}_paired.fq.gz \
    --readFilesCommand zcat \
    --outSAMtype BAM SortedByCoordinate \
    --outSAMattrRGline "ID:$fastqId SM:$fastqId PL:ILLUMINA" \
    --twopassMode "Basic" \
    --outFileNamePrefix $starTmpDir/$fastqId

# Index the output BAM file
module load SAMtools/1.9-foss-2018b
module list

samtools index \
    -@ $cpus \
    $starTmpDir/$fastqId*.bam
EOF
)
echoInfo "$stepName was submitted: $STARMappingJobId ..."
# } // Mapping reads to genome 


#
## WASP: Find intersected SNPs {
#
dependency=$afterok:$STARMappingJobId
stepName=WaspRMBFindIntersectedSnps
mem=8G
cpus=1
time=0:49:00

WaspRMBFindIntersectedSnpsJobId=$(sbatch $dependency \
    --mem=$mem \
    --time=$time \
    --cpus-per-task=$cpus \
    --job-name=$fastqId-$stepName \
    --output=$logDir/%j-$fastqId-$stepName.log \
    <<EOF | cut -f4 -d' '
#!/bin/bash
set -Ee -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

module load HDF5/1.8.14-foss-2018b Python/3.7.4-GCCcore-7.3.0-bare
module list

if [ $pyEnv"xxx" != "xxx" ]; then source $pyEnv/bin/activate; fi

# Find intersecting SNPs
python $waspDir/mapping/find_intersecting_snps.py \
    --is_sorted \
    --is_paired_end \
    --output_dir $workDir/tmpDir/$fastqId/waspTmpDir \
    --snp_tab $snpH5dbPath/snps_tab.h5 \
    --snp_index $snpH5dbPath/snps_index.h5 \
    --haplotype $snpH5dbPath/haplotype.h5 \
    --samples $sampleId \
    $workDir/tmpDir/$fastqId/starTmpDir/*.bam
EOF
)
echoInfo "$stepName was submitted: $WaspRMBFindIntersectedSnpsJobId ..."
# } // Find intersected SNPs


#
## STAR: Remapping by STAR for WASP {
#
dependency=$afterok:$WaspRMBFindIntersectedSnpsJobId
stepName=WaspRMBRemapping
mem=50G
cpus=5
time=0:29:00

WaspRMBRemappingJobId=$(sbatch $dependency \
    --time=$time --mem=$mem --cpus-per-task=$cpus \
    --output=$workDir/logDir/%j-$fastqId-$stepName.log \
    --job-name=$fastqId-$stepName \
    <<EOF | cut -f4 -d' '
#!/bin/bash
set -Ee -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

module load STAR/2.6.1c-foss-2018b
module list

STAR \
    --runMode alignReads \
    --genomeDir $genomeDir \
    --runThreadN $cpus \
    --readFilesIn $waspTmpDir/*remap.fq1.gz $waspTmpDir/*remap.fq2.gz \
    --readFilesCommand zcat \
    --outSAMtype BAM SortedByCoordinate \
    --outSAMattrRGline "ID:$fastqId SM:$fastqId PL:ILLUMINA" \
    --twopassMode "Basic" \
    --outFileNamePrefix $waspTmpDir/$fastqId.remap

# Create index files for BAMs
module load SAMtools/1.9-foss-2018b
module list

samtools index -@ $cpus $waspTmpDir/$fastqId.remap*.bam
EOF
)
echoInfo "$stepName was submitted: $WaspRMBRemappingJobId ..."
# } // STAR: Remapping by STAR for WASP


#
## WASP: RMB filtering and removing duplication {
#
dependency=$afterok:$WaspRMBRemappingJobId
stepName=WaspRMBFilterAndRmDup
mem=10G
cpus=1
time=0:39:00

waspDir=${waspDir:=~/tools/WASP}
WaspRMBFilterAndRmDupJobId=$(sbatch $dependency \
    --mem=$mem 
    --time=$time 
    --cpus-per-task=$cpus \
    --job-name=$fastqId-$stepName \
    --output=$workDir/logDir/%j-$fastqId-$stepName.log \
    <<EOF | cut -f4 -d' '
#!/bin/bash
set -Ee -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc
# Find intersecting SNPs
module load HDF5/1.8.14-foss-2018b Python/3.7.4-GCCcore-7.3.0-bare
module list

if [ $pyEnv"xxx" != "xxx" ]; then source $pyEnv/bin/activate; fi

# TODO: 需要根据上一步输出，修改输入文件名
python $waspDir/mapping/filter_remapped_reads.py \
    $waspTmpDir/${fastqId}.to.remap.bam \
    $waspTmpDir/${fastqId}.remap.bam \
    $waspTmpDir/${fastqId}.remap.keep.bam
    

# Merge original and remapped BAM
module load SAMtools/1.9-foss-2018b
module list

samtools merge \
    $waspTmpDir/${fastqId}.keep.merged.bam \
    $waspTmpDir/${fastqId}.remap.keep.bam \
    $waspTmpDir/${fastqId}.keep.bam

samtools sort \
    -@ $cpus \
    -o $waspTmpDir/${fastqId}.keep.merged.bam \
    $waspTmpDir/${fastqId}.keep.merged.sorted.bam

samtools index \
    -@ $cpus \
    $waspTmpDir/${fastqId}.keep.merged.sorted.bam


# Remove duplications
module load HDF5/1.8.14-foss-2018b Python/3.7.4-GCCcore-7.3.0-bare
module list

if [ $pyEnv"xxx" != "xxx" ]; then source $pyEnv/bin/activate; fi

python $waspDir/mapping/rmdup_pe.py \
    $waspTmpDir/${fastqId}.keep.merged.sorted.bam \
    $waspTmpDir/${fastqId}.keep.merged.sorted.rmdup.bam


# Get Allele-specific read counts
module load HDF5/1.8.14-foss-2018b Python/3.7.4-GCCcore-7.3.0-bare
module list

if [ $pyEnv"xxx" != "xxx" ]; then source $pyEnv/bin/activate; fi

python $waspDir/CHT/bam2h5.py \
    --chrom $chromInfoFile \
    --individual $sampleId \
    --snp_index $snpH5dbPath/snps_index.h5 \
    --snp_tab $snpH5dbPath/snps_tab.h5 \
    --haplotype $snpH5dbPath/haplotype.h5 \
    --read_counts $waspTmpDir/${fastqId}.allAlleleReadCounts.h5 \
    --txt_counts $waspTmpDir/${fastqId}.allAlleleReadCounts.txt \
    --ref_as_counts $waspTmpDir/${fastqId}.refAlleleReadCounts.h5 \
    --alt_as_counts $waspTmpDir/${fastqId}.altAlleleReadCounts.h5 \
    --other_as_counts $waspTmpDir/${fastqId}.otherAlleleReadCounts.h5 \
    $waspTmpDir/${fastqId}.keep.merged.sorted.rmdup.bam \
    2> /dev/null
EOF
)

echoInfo "$stepName was submitted: $WaspRMBFilterAndRmDupJobId ..."
# } // WASP: RMB filtering and removing duplication


#
## GATK: ASEReadCounter counts reads allelicly {
#
dependency=$afterok:$WaspRMBFilterAndRmDupJobId
stepName=GatkASEReaderCounter
mem=25G
cpus=1
time=0:9:00

GatkASEReaderCounterJobId=$(sbatch $dependency \
    --mem=$mem \
    --time=$time \
    --cpus-per-task=$cpus \
    --job-name=$fastqId-$stepName \
    --output=$workDir/logDir/%j-$fastqId-$stepName.log \
    <<EOF | cut -d' ' -f4
#!/bin/bash
set -Ee -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

module load GATK
module list

gatk ASEReadCounter \
    --input xxx \
    --variant xxx \
    --reference xxx \
    --output-format csv \
    --output xxx
EOF
)
# } // GATK: ASEReadCounter counts reads allelicly

#
## RASQUAL estimates ASE effects {
#
dependency=$afterok:$WaspRMBFilterAndRmDupJobId:$GatkASEReaderCounterJobId
stepName=RasqualASEEstimation
mem=25G
cpus=1
time=0:9:00

RasqualASEEstimationJobId=$(sbatch $dependency \
    --mem=$mem \
    --time=$time \
    --cpus-per-task=$cpus \
    --job-name=$fastqId-$stepName \
    --output=$workDir/logDir/%j-$fastqId-$stepName.log \
    <<EOF | cut -d' ' -f4
#!/bin/bash
set -Ee -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

EOF
# } // RASQUAL estimates ASE effects

#
## Collect output and clean up {
#
dependency=$afterok:$GatkASEReaderCounterJobId:
stepName=CollectOutputAndCleanup
mem=4G
cpus=1
time=0:9:00

CollectOutputAndCleanupJobId=$(sbatch $dependency \
    --mem=$mem \
    --time=$time \
    --cpus-per-task=$cpus \
    --job-name=$fastqId-$stepName \
    --output=$workDir/logDir/%j-$fastqId-$stepName.log \
    <<EOF | cut -d' ' -f4
#!/bin/bash
set -Ee -o pipefail
[[ -f /apps/modules/modules.bashrc ]] && source /apps/modules/modules.bashrc

# Compress all logfiles as some of them are large.
gzip $logDir/*$fastqId-*.log

# Copy fastp reports to output directory.
cp -fr $fastpTmpDir/*.{html,json} $fastpOptDir

# Copy WASP all counts per chromosome in HDF5 format.
for chr in {1..22}; do
    if [[ -d $workDir/tmpDir/$fastqId/waspTmpDir/perChrom/\$chr ]]; then
        mkdir -p $workDir/optDir/$fastqId/waspOptDir/perChrom/\$chr
        cp -fr $workDir/tmpDir/$fastqId/waspTmpDir/perChrom/\$chr/*.h5 \
            $workDir/optDir/$fastqId/waspOptDir/perChrom/\$chr
    fi
done

# Merge WASP allelic read counts in text format from each chromosome.
cat $workDir/tmpDir/$fastqId/waspTmpDir/perChrom/*/*.readCountsInText.txt \
    > $workDir/optDir/$fastqId/waspOptDir/$fastqId.readCountsInText.txt

# cp -fr $workDir/tmpDir/$fastqId/starTmpDir/*.bam $workDir/optDir/$fastqId/starOptDir
# module purge && module load SAMtools/1.9-foss-2018b && module list
# samtools merge -fcp -@ $cpus \
#     $workDir/optDir/$fastqId/waspOptDir/$fastqId.keep.merge.rmdup.bam \
#     $workDir/tmpDir/$fastqId/waspTmpDir/perChrom/*/*.keep.merged.sorted.rmdup.sorted.bam
# 
# samtools sorted -@ $cpus \
#     -o $workDir/optDir/$fastqId/waspOptDir/$fastqId.keep.merge.rmdup.sorted.bam \
#     $workDir/optDir/$fastqId/waspOptDir/$fastqId.keep.merge.rmdup.bam
# 
# samtools index -@ $cpus \
#     $workDir/optDir/$fastqId/waspOptDir/$fastqId.keep.merge.rmdup.sorted.bam
# 
# rm -fr $workDir/optDir/$fastqId/waspOptDir/$fastqId.keep.merge.rmdup.bam

# rm -fr $workDir/tmpDir/$fastqId
# rm -fr $workDir/tmpDir/$fastqId"_"R{1,2}.fq.gz
EOF
)

echoInfo "$stepName was submitted. Job id: $CollectOutputAndCleanupJobId ..."
# } // Collect output and clean up

# vim: set ai nowrap nospell ft=sh:
